# Blockchain-Based Log Integrity System Architecture

## System Overview

This system provides tamper-evident logging by creating cryptographic proofs of log integrity and anchoring them on a blockchain. The architecture follows a modular design with components that handle specific aspects of the log collection, processing, and verification workflow.

## Components

### 1. Log Generator (Test Component)

**Purpose**: Simulate log creation for testing the system.

**Implementation**:
- Node.js CLI application that generates sample logs
- Configurable log formats and generation rates
- Writes logs to files that are monitored by the Log Shipper

### 2. Log Shipper/Agent

**Purpose**: Collect logs from sources and forward them to the aggregation service.

**Implementation**:
- Lightweight Node.js process
- File-watching using Chokidar library
- HTTP client (Axios) for sending logs to the Aggregation Service
- Local buffering for handling network interruptions

**Key Flows**:
1. Watch log files for changes
2. Parse new log entries
3. Send logs to the Aggregation Service
4. Buffer logs locally if the service is unavailable
5. Retry sending buffered logs when the service becomes available

### 3. Log Aggregation Service

**Purpose**: Core backend service that processes logs and interacts with the blockchain.

**Implementation**:
- Express.js server for the API endpoints
- MerkleTree.js for Merkle tree processing
- Ethers.js for blockchain integration
- Node-schedule for batch processing
- File-based storage for logs and metadata

**Key Flows**:
1. Receive logs through the API
2. Store incoming logs temporarily
3. Process logs in batches at scheduled intervals
4. Create Merkle trees from log batches
5. Calculate Merkle root and proofs
6. Store Merkle root on the blockchain
7. Archive processed logs with their proofs

**Modules**:
- **API**: Exposes endpoints for receiving logs and verifying their integrity
- **Merkle Processing**: Creates Merkle trees and calculates proofs
- **Blockchain Integration**: Communicates with the Ethereum smart contract
- **Storage**: Handles temporary and archive storage of logs

### 4. Smart Contract

**Purpose**: Store Merkle roots on the blockchain as immutable anchors.

**Implementation**:
- Solidity contract deployed on Ethereum Sepolia testnet
- Basic access control for write operations
- Simple storage pattern for Merkle roots

**Functions**:
- `storeMerkleRoot(bytes32 _merkleRoot)`: Store a new Merkle root
- `getMerkleRoot(uint256 _batchId)`: Retrieve a stored root by batch ID
- `getLatestBatchId()`: Get the latest batch ID

### 5. Verification Tool

**Purpose**: Allow auditors to verify the integrity of specific log entries.

**Implementation**:
- Node.js CLI application
- MerkleTree.js for verification
- Ethers.js for blockchain interaction

**Key Flows**:
1. Accept log entry data and batch ID
2. Retrieve log entry and Merkle proof from archive
3. Fetch corresponding Merkle root from blockchain
4. Verify log entry against the root using the proof
5. Display verification result

### 6. Log Archive

**Purpose**: Store logs long-term with their verification metadata.

**Implementation**:
- File-based storage (JSON files)
- Organized by batch ID
- Stores raw logs, Merkle proofs, and batch metadata

### 7. Web UI

**Purpose**: Provide visual interface for system monitoring, log verification, and demonstration.

**Implementation**:
- React application with Material-UI
- Visualization components for the verification process
- Integration with the Aggregation Service API

**Features**:
- Dashboard showing system status
- Log search and browsing
- Verification interface
- Visual explanation of how the system works

## Data Flow

1. **Log Collection**:
   - Logs are generated by applications (simulated by Log Generator)
   - Log Shipper monitors log files and sends new entries to the Aggregation Service
   - Aggregation Service stores incoming logs temporarily

2. **Batch Processing**:
   - At fixed intervals, the Aggregation Service processes accumulated logs
   - Logs are hashed and arranged in a Merkle tree
   - The Merkle root is calculated and sent to the smart contract
   - Each log entry's Merkle proof is generated
   - Logs and proofs are stored in the Log Archive

3. **Verification**:
   - When verification is requested, the system retrieves:
     - The log entry from the archive
     - Its corresponding Merkle proof
     - The Merkle root from the blockchain
   - The verification process confirms if the log entry's hash, combined with its proof, reconstructs the stored Merkle root

## Security Considerations

- **Authentication**: Basic authentication for API endpoints
- **Access Control**: Only authorized addresses can store Merkle roots on the blockchain
- **Data Integrity**: Cryptographic verification ensures logs cannot be tampered with
- **Transparency**: All blockchain transactions are publicly verifiable

## Deployment Architecture

In a production environment, the components would be deployed as follows:

- Log Shipper: On each log-producing server
- Aggregation Service: Centralized service with high availability
- Smart Contract: Deployed once on Ethereum Sepolia testnet
- Web UI: Hosted application accessible to auditors
- Verification Tool: Used by auditors to verify logs
- Log Archive: Secured storage with backup and retention policies
